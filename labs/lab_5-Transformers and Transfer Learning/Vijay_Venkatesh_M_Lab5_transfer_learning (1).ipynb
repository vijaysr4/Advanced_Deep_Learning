{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlAfI8mCWAf3"
      },
      "source": [
        "<center>\n",
        "<h1><br/></h1>\n",
        "<h1>INF581A: Advanced Deep Learning</h1>\n",
        "<h2>Lab 5: Transformer and Transfer Learning</h2>\n",
        "\n",
        "<h5>Tuesday, February 04, 2025</h5>\n",
        "<br>\n",
        "</center>\n",
        "\n",
        "<hr style=\"border:10px solid gray\"> </hr>\n",
        "<p style=\"text-align: justify;\">\n",
        "This handout includes theoretical introductions, <font color='blue'>coding tasks</font> and <font color='red'>questions</font>. Before the deadline, you should submit to Moodle a <B>.ipynb</B> file named <b>Lastname_Firstname.ipynb</b> containing your notebook (with the gaps filled and your answers to the questions). Your answers should be well constructed and well justified. They should not repeat the question or generalities in the handout. When relevant, you are welcome to include figures, equations and tables derived from your own computations, theoretical proofs or qualitative explanations. One submission is required for each student. The deadline for this lab is <b>February 11\n",
        ", 2025 11:59 AM</b>. No extension will be granted. Late policy is as follows: ]0, 24] hours late → -5 pts; ]24, 48] hours late → -10 pts; > 48 hours late → not graded (zero).\n",
        "</p>\n",
        "<hr style=\"border:5px solid gray\"> </hr>\n",
        "\n",
        "<h3><b>1. Introduction:</b></h2>\n",
        "<p style=\"text-align: justify;\">\n",
        "Transfer learning that is, solving tasks with models that have been pretrained on very large amounts of data, was a game changer in many deep learning tasks. In NLP, while annotated data are scarce, raw text is virtually unlimited and readily available. Thus, the ability to learn good representations from plain text could greatly improve general natural language understanding. Learning without labels is enabled via self-supervised learning, a setting in which a system learns to predict part of its input from other parts of its input.\n",
        "\n",
        "<p>One way to realise this pre-training is to use <i>generative pre-training</i> <a href=\"https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf\" target='_blank'>[1]</a> of a language model. In this pre-training phase, the model will learn to predict the next tokens in a sequence given the previous ones.</p>\n",
        "<p>Thus, this phase does not require any type of annotations apart from the input text itself. Once the language model is sufficiently pre-trained, it can be fine-tuned on supervised tasks while requiring minimal changes to its architecture (replacing the classification head).</p>\n",
        "\n",
        "In this lab we will:\n",
        "<ul>\n",
        "    <li>Implement and pretrain a language model with transformer architecture.</li>\n",
        "    <li>Use the pretrained model (transfer learning) to perform a sentiment analysis task which consists of classifying some books reviews into positive and negative ones.</li>\n",
        "    <li>Compare the performance of the pretrained model to a model trained from scratch.</li>\n",
        "</ul>\n",
        "\n",
        "<h3><b>2. The Model:</b></h3>\n",
        "<p style=\"text-align: justify;\">\n",
        "\n",
        "Our model is based on Transformers<a href=\"https://arxiv.org/abs/1706.03762\" target='_blank'>[2]</a>. While the Transformer is a model that follows the encoder-decoder structure, it is possible to use only the encoder part (as in BERT) or the decoder part (as in gpt) to perform some specific tasks. In this notebook, we use a multi-layer Transformer decoder for the language model. Fortunatly, PyTorch recent releases include a standard transformer blocks that can be easily used and adapted.\n",
        "\n",
        "Let's start by implementing the model. The different layers used in this model are the following:\n",
        "\n",
        "- The embedding layer\n",
        "- Positional Embedding\n",
        "- The transformer layers\n",
        "- Linear layer for decoding and classification\n",
        "<center>\n",
        "<img src='https://am3pap003files.storage.live.com/y4m6sN7mGXA8_lmRiUuuAAbecrSrMa1IumytUCiEJEkIKuoKV2uNoqTmo6mU_PadFeMESJTRjNbM3Q9qIRMiXLMxPDBdKKFC5cX5UFslx44IxVGXBAI7Cipp5A38tVQdwrioDNyWAMIbYb7dQTXoa0T6oRDBl1kgGn2D9JV8wuna3Jhrsd3TgPQNZZnoO9ZpmaN?width=815&height=680&cropmode=none' alt=\"Drawing\" width= '500px'/>\n",
        "\n",
        "The same model can be used for language modeling and classification by just replacing the last layer in the model. This is why we split our model into two modules:\n",
        "\n",
        "- base module: which consists of the 3 first layers.\n",
        "- classifier module: which consists of the last layer.\n",
        "\n",
        "After the pretraining, the parameters of the base model can be \"transferred\" to the model used in the classfication task, while the classifier module should be replaced by a new head initialized randomly.\n",
        "\n",
        "Some of the code is adapted from this nice tutorial: <a href=\"https://pytorch.org/tutorials/beginner/transformer_tutorial.html\" target=\"_blank\">https://pytorch.org/tutorials/beginner/transformer_tutorial.html</a>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqukuIe0Rb_c"
      },
      "source": [
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Optional, List\n",
        "\n",
        "import torch\n",
        "from torch import Tensor\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<b><h4><font color='blue'>\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "Task 1: </b><br>\n",
        "Fill in the gaps in the `TransformerModel()` class to implement the described model.\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "</font></h4>"
      ],
      "metadata": {
        "id": "roNlBhkJPIrk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FF6fjkqgN39"
      },
      "source": [
        "### The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0cj9WkSFQwl"
      },
      "source": [
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self,\n",
        "                 ntoken: int,\n",
        "                 nhead: int,\n",
        "                 nhid: int,\n",
        "                 nlayers: int,\n",
        "                 dropout: float = 0.5) -> None:\n",
        "        super(TransformerModel, self).__init__()\n",
        "        '''\n",
        "        ntokens: the size of vocabulary\n",
        "        nhid: the hidden dimension of the model.\n",
        "        We assume that embedding_dim = nhid\n",
        "        nlayers: the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "        nhead: the number of heads in the multiheadattention models\n",
        "        dropout: the dropout value\n",
        "         '''\n",
        "        self.model_type = \"Transformer\"\n",
        "        self.encoder = nn.Embedding(ntoken, nhid) # fill me, nhid = the dim_embed\n",
        "        self.pos_encoder = PositionalEncoding(nhid, dropout) #fill me, the PositionalEncoding class is implemented in the next cell\n",
        "        encoder_layers = nn.TransformerEncoderLayer(\n",
        "            d_model=nhid,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=nhid,  # here we assume the feedforward dimension equals nhid\n",
        "            dropout=dropout\n",
        "            ) #fill me we assume nhid = d_model = dim_feedforward\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=nlayers) #fill me\n",
        "        self.nhid = nhid\n",
        "        self.init_weights()\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz: int) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Generate a square mask for the sequence to prevent attention to future tokens.\n",
        "\n",
        "        Args:\n",
        "            sz (int): Size of the square mask (sequence length).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Mask tensor of shape [sz, sz].\n",
        "        \"\"\"\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = (\n",
        "            mask.float()\n",
        "            .masked_fill(mask == 0, float(\"-inf\"))\n",
        "            .masked_fill(mask == 1, float(0.0))\n",
        "        )\n",
        "        return mask\n",
        "\n",
        "    def init_weights(self) -> None:\n",
        "        \"\"\"Initialize the weights of the encoder.\"\"\"\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self,\n",
        "                src: torch.Tensor,\n",
        "                src_mask: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass through the Transformer model.\n",
        "\n",
        "        Args:\n",
        "            src (torch.Tensor): Input tensor of shape [seq_len, batch_size].\n",
        "            src_mask (torch.Tensor): Square subsequent mask of shape [seq_len, seq_len].\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor from the transformer encoder.\n",
        "        \"\"\"\n",
        "        src = self.encoder(src) * math.sqrt(self.nhid)\n",
        "        src = self.pos_encoder(src)\n",
        "        output = self.transformer_encoder(src, src_mask)\n",
        "        return output\n",
        "\n",
        "\n",
        "class ClassificationHead(nn.Module):\n",
        "    def __init__(self,\n",
        "                 nhid: int,\n",
        "                 nclasses: int) -> None:\n",
        "        \"\"\"\n",
        "        Initialize the classification head.\n",
        "\n",
        "        Args:\n",
        "            nhid (int): Hidden dimension size.\n",
        "            nclasses (int): Number of output classes.\n",
        "        \"\"\"\n",
        "        super(ClassificationHead, self).__init__()\n",
        "        self.decoder = nn.Linear(nhid, nclasses)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self) -> None:\n",
        "        \"\"\"Initialize the weights of the decoder.\"\"\"\n",
        "        initrange = 0.1\n",
        "        self.decoder.bias.data.zero_()\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass through the classification head.\n",
        "\n",
        "        Args:\n",
        "            src (torch.Tensor): Input tensor from the Transformer model.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Logits for each class.\n",
        "        \"\"\"\n",
        "        output = self.decoder(src)\n",
        "        return output\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self,\n",
        "                 ntoken: int,\n",
        "                 nhead: int,\n",
        "                 nhid: int,\n",
        "                 nlayers: int,\n",
        "                 nclasses: int,\n",
        "                 dropout: float = 0.5) -> None:\n",
        "        \"\"\"\n",
        "        Initialize the complete model combining the Transformer base and the classification head.\n",
        "\n",
        "        Args:\n",
        "            ntoken (int): Vocabulary size.\n",
        "            nhead (int): Number of attention heads.\n",
        "            nhid (int): Hidden dimension size.\n",
        "            nlayers (int): Number of Transformer encoder layers.\n",
        "            nclasses (int): Number of output classes.\n",
        "            dropout (float, optional): Dropout probability. Defaults to 0.5.\n",
        "        \"\"\"\n",
        "        super(Model, self).__init__()\n",
        "        self.base = TransformerModel(ntoken, nhead, nhid, nlayers, dropout)\n",
        "        self.classifier = ClassificationHead(nhid, nclasses)\n",
        "\n",
        "    def forward(self,\n",
        "                src: torch.Tensor,\n",
        "                src_mask: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass through the full model.\n",
        "\n",
        "        Args:\n",
        "            src (torch.Tensor): Input tensor of shape [seq_len, batch_size].\n",
        "            src_mask (torch.Tensor): Mask tensor of shape [seq_len, seq_len].\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output logits from the classifier.\n",
        "        \"\"\"\n",
        "        # base model\n",
        "        x = self.base(src, src_mask)\n",
        "        # classifier model\n",
        "        output = self.classifier(x)\n",
        "        return output"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kt2QQohaFZry"
      },
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "  # for a more in depth explanation we encourage you to read:\n",
        "  # https://medium.com/swlh/elegant-intuitions-behind-positional-encodings-dc48b4a4a5d1\n",
        "    def __init__(self,\n",
        "                 nhid: int,\n",
        "                 dropout: float = 0.1,\n",
        "                 max_len: int = 5000) -> None:\n",
        "        \"\"\"\n",
        "        Initialize the PositionalEncoding module.\n",
        "\n",
        "        Args:\n",
        "            nhid (int): The hidden (and embedding) dimension.\n",
        "            dropout (float, optional): Dropout probability. Defaults to 0.1.\n",
        "            max_len (int, optional): Maximum length for which to precompute positional encodings. Defaults to 5000.\n",
        "        \"\"\"\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, nhid)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, nhid, 2).float() * (-math.log(10000.0) / nhid)\n",
        "        )\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self,\n",
        "                x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Add positional encodings to the input embeddings.\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): Input tensor of shape [sequence_length, batch_size, embedding_dim].\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Tensor with positional encodings added, of the same shape as input.\n",
        "        \"\"\"\n",
        "        x = x + self.pe[: x.size(0), :]\n",
        "        return self.dropout(x)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b><h4><font color='red'>\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "Question 1 (4 points): </b><br>\n",
        "What is the role of the square mask in our implementation? What about the positional encoding?\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "</font></h4>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "H1FwuPBuPyFT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b><h4><font color='green'>\n",
        "<hr style=\"border:10px solid green\"> </hr>\n",
        "Answer 1: </b><br>\n",
        "\n",
        "#### Square Mask\n",
        "\n",
        "It prevents a token from “seeing” future tokens during attention computations.\n",
        "\n",
        "The mask is a square matrix (of shape```[sequence_length, sequence_length]```) that prevents a given token from attending to tokens that come later in the sequence. It does this by setting the attention scores for future tokens to negative infinity, so that after applying the softmax, these positions contribute effectively zero weight.\n",
        "\n",
        "This ensures that when predicting a token at position $i$, the model only uses information from positions $ ≤ i$, thus avoiding any information leakage from the future.\n",
        "\n",
        "\n",
        "#### Positional Encoding\n",
        "\n",
        "It gives ordering information into the input embeddings, allowing the transformer to differentiate between tokens based on their positions in the sequence.\n",
        "\n",
        "The positional encoding is added to the token embeddings and typically uses sinusoidal functions to generate a unique positional representation for each token based on its index in the sequence. So the model gains access to information about the relative or absolute position of tokens in the sequence, enabling it to capture sequential relationships.\n",
        "\n",
        "<hr style=\"border:10px solid green\"> </hr>\n",
        "</font></h4>\n",
        "\n"
      ],
      "metadata": {
        "id": "IB9wyvMUP8FZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b><h4><font color='red'>\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "Question 2 (2 points): </b><br>\n",
        "Why do we have to replace the classification head? What is the main difference between the <i>language modeling</i> and the <i>classification</i> tasks?\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "</font></h4>\n"
      ],
      "metadata": {
        "id": "q7PIyZg4U4oG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b><h4><font color='green'>\n",
        "<hr style=\"border:10px solid green\"> </hr>\n",
        "Answer 2: </b><br>\n",
        "\n",
        "The current model learns to predict the next word by outputting scores for every word in a large vocabulary. For the classification task (like deciding if a review is positive or negative), we only need to pick one label out of a few options. That’s why we remove the pretraining head and replace it with a new one designed to give just a few outputs (one for each class).\n",
        "\n",
        "In language modeling, the goal is to predict the next word at each step, so the model works at the word level. In contrast, classification requires the model to look at the whole sentence or review and decide on one overall label.\n",
        "\n",
        "```Example:```\n",
        "- For language modeling:  given the input \"The cat sat on the\", the model predicts the next word from a vocabulary of 10,000 words.\n",
        "- For sentiment classification: given a full review like \"The movie was fantastic\", the model only needs to decide between 2 labels: positive or negative.\n",
        "\n",
        "That's why we replace the head: the original head outputs 10,000 options, but for classification we only need 2.\n",
        "\n",
        "<hr style=\"border:10px solid green\"> </hr>\n",
        "</font></h4>\n",
        "\n"
      ],
      "metadata": {
        "id": "3EU6M747VMEp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b><h4><font color='red'>\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "Question 3 (6 points): </b><br>\n",
        "How many trainable parameters does the model have in the case of <br>\n",
        "<ul>\n",
        "<font color='red'>\n",
        "    <li><i>language modeling</i> task.</li>\n",
        "    <li><i>classification</i> task.</li>\n",
        "</ul>\n",
        "Please detail your answer. You can omit the biases and the parameters of normalization layers.<br>\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "</font></h4>\n",
        "\n"
      ],
      "metadata": {
        "id": "eIHvBUqGVeH0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b><h4><font color='green'>\n",
        "<hr style=\"border:10px solid green\"> </hr>\n",
        "Answer 3: </b><br>\n",
        "\n",
        "We denote:\n",
        "- $$V = vocabulary\\ size $$\n",
        "\n",
        "- $$d = hidden\\ (and\\ embedding)\\ dimension$$\n",
        "- $$L = number\\ of\\ Transformer\\ layers$$\n",
        "- $$C = number\\ of\\ classes\\ (for\\ language\\ modeling, C = V; for\\ classification, e.g., C = 2)$$\n",
        "\n",
        "---\n",
        "\n",
        "1. **Embedding Layer**  \n",
        "   The embedding layer has:  \n",
        "   $$\\text{Parameters} = V \\times d = Vd$$\n",
        "\n",
        "2. **Transformer Encoder Layers**  \n",
        "   Each Transformer layer consists of two parts:\n",
        "\n",
        "   ** Multi-head Self-Attention:**  \n",
        "   - Combined projection for query, key, and value: $3d^2$  \n",
        "   - Output projection: $d^2$  \n",
        "     \n",
        "   Total for attention: $3d^2 + d^2 = 4d^2$\n",
        "\n",
        "   **Feed-Forward Network:**  \n",
        "   - First linear layer: $d^2$  \n",
        "   - Second linear layer: $d^2$  \n",
        "     \n",
        "   Total for feed-forward: $d^2 + d^2 = 2d^2$\n",
        "\n",
        "   **Total per layer:** $4d^2 + 2d^2 = 6d^2$\n",
        "\n",
        "   For $L$ layers, the total is: $6L\\,d^2$\n",
        "\n",
        "3. **Final Linear Layer**  \n",
        "   This layer maps from the hidden dimension to the output dimension: $\\text{Parameters} = d \\times C = dC$\n",
        "\n",
        "---\n",
        "\n",
        "**Overall Total Trainable Parameters:**  $\\text{Total} = Vd + 6L\\,d^2 + dC$\n",
        "\n",
        "---\n",
        "\n",
        "- **For the Language Modeling Task:**  \n",
        "  Here, the output layer predicts over the entire vocabulary, so $C = V$. Then,  \n",
        "  $$\\text{Total}_{\\text{LM}} = Vd + 6L\\,d^2 + dV = 2Vd + 6L\\,d^2$$\n",
        "\n",
        "- **For the Classification Task:**  \n",
        "  For example, if there are 2 classes, then $C = 2$. Thus,  \n",
        "  $$\\text{Total}_{\\text{CLS}} = Vd + 6L\\,d^2 + 2d$$\n",
        "\n",
        "\n",
        "<hr style=\"border:10px solid green\"> </hr>\n",
        "</font></h4>\n"
      ],
      "metadata": {
        "id": "LLrionbqV3Sf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfEYHJx2JW6l"
      },
      "source": [
        "Let's verify if our model works, by applying one inference step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhb2gkUhJMR0",
        "outputId": "edae519a-f194-422c-c41b-a13a1b836ed9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "ntokens = 100  # the size of vocabulary\n",
        "nhid = 200  # hidden dimension\n",
        "nlayers = 4  # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2  # the number of heads in the multiheadattention models\n",
        "dropout = 0  # the dropout value\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens, dropout).to(device)\n",
        "dummy_input = torch.tensor([[2, 6, 2, 5, 43, 21]]).to(device)\n",
        "src_mask = model.base.generate_square_subsequent_mask(1).to(device)\n",
        "out = model.forward(dummy_input, src_mask)\n",
        "\n",
        "print(out.shape) # is it the right shape?\n",
        "# Yes the shape is right\n",
        "# torch.Size([1, 6, 100])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 6, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i74NN897Fcit"
      },
      "source": [
        "## 3.Vocabulary and Tokenization\n",
        "\n",
        "To train the language model, the text in our corpus should be first tokenized. We use sentencepiece <a href=\"https://github.com/google/sentencepiece\">https://github.com/google/sentencepiece</a> that implements byte-pair-encoding (BPE), a sub-word tokenization algorithm.<br>\n",
        "The vocabulay is given in <code>dict.txt</code> file. Let's load it, and map each token to a unique index.<br>\n",
        "\n",
        "In our experiments we use datasets that are already tokenized.\n",
        "\n",
        "\n",
        "<b><h4><font color='blue'>\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "Task 2: </b><br>\n",
        "Fill in the gaps to create a <code>token2ind</code> and <code>ind2token</code> mapping dictionaries\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "</font></h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qjd26ghWuff",
        "outputId": "9f412ba0-db4c-4164-eeaa-9bee81920bf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/dict.txt\n",
        "!head -5 dict.txt"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-11 09:43:07--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/dict.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 577587 (564K) [text/plain]\n",
            "Saving to: ‘dict.txt.1’\n",
            "\n",
            "dict.txt.1          100%[===================>] 564.05K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2025-02-11 09:43:08 (83.7 MB/s) - ‘dict.txt.1’ saved [577587/577587]\n",
            "\n",
            "▁d 1\n",
            "es 1\n",
            "▁l 1\n",
            "en 1\n",
            "on 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFdH_-JeFbGA",
        "outputId": "be3abaa5-d622-48e9-e38d-8ac627ae46aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "path_vocab = \"dict.txt\"\n",
        "token2ind = {\"<sos>\": 0, \"<pad>\": 1, \"<eos>\": 2, \"<oov>\": 3} # the 4 first indices are reserved to special tokens\n",
        "offset = len(token2ind)\n",
        "\n",
        "with open(path_vocab, \"r\") as f:\n",
        "    for idx, line in enumerate(f):\n",
        "        word = line.split()[0].strip()\n",
        "        token2ind[word] = idx + offset\n",
        "\n",
        "ind2token =  {v: k for k, v in token2ind.items()}\n",
        "\n",
        "print(ind2token[1111])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▁trop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOExGODajN8p"
      },
      "source": [
        "## 4.Data Loader\n",
        "We use the <code>DataLoader</code> class, to load our dataset and generate the mini-batches used in the training. <code>get_loader()</code> returns a <code>DataLoader</code>  object, which is an iterable over data samples. The data loader can return mini-batches for language modeling or sequence classification based on the <code>task</code> argument that we pass to <code>get_loader()</code> function. Currently the function supports <i>language_modeling</i> and <i>classification</i> tasks.<br>\n",
        "\n",
        "For the <i>language_modeling</i> task, both the input and the target are batches of sequences. In fact, the target is basically a shifted version of\n",
        "the input, in such a way that each token is predicted given all previous tokens. For example, for a sequence A B C D: <br>\n",
        "<b>Input:</b><code>\\<sos\\></code>A B C D<br>\n",
        "<b>Output:</b>A B C D<code>\\<eos\\></code><br>\n",
        "\n",
        "For the <i>classification</i> task,\n",
        "the input is a batch of sequences and\n",
        "the target is a batch of scalar labels.<br>\n",
        "For more information about data loaders check: <a href=\"https://pytorch.org/docs/stable/data.html\">https://pytorch.org/docs/stable/data.html</a>\n",
        "\n",
        "\n",
        "<b><h4><font color='blue'>\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "Task 3: </b><br>\n",
        "Fill in the gap inside <code>Dataset</code> class in order to create the input sequence\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "</font></h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0jN-Ar9i5Q1"
      },
      "source": [
        "import numpy\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "\n",
        "class Dataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        path_documents,\n",
        "        path_labels=None,\n",
        "        token2ind={},\n",
        "        max_len=512,\n",
        "        task=\"language_modeling\",\n",
        "    ):\n",
        "        self.task = task\n",
        "        self.max_len = max_len\n",
        "        self.token2ind = token2ind\n",
        "        self.documents = []\n",
        "        self.labels = []\n",
        "        with open(path_documents, \"r\") as f1:\n",
        "            for line in f1:\n",
        "                self.documents.append(line.strip())\n",
        "        if task == \"classification\":\n",
        "            with open(path_labels, \"r\") as f1:\n",
        "                for line in f1:\n",
        "                    self.labels.append(int(line.strip()))\n",
        "            assert len(self.labels) == len(self.documents)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.documents)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sequence = self.documents[index].split()\n",
        "        if len(sequence) > self.max_len - 1:\n",
        "            sequence = sequence[: self.max_len - 1]\n",
        "        source_sequence = [self.token2ind[\"<sos>\"]] + [\n",
        "            self.token2ind.get(token, self.token2ind[\"<oov>\"]) for token in sequence\n",
        "        ]\n",
        "\n",
        "        if self.task == \"language_modeling\":\n",
        "            target = source_sequence[1:]\n",
        "            target.append(self.token2ind[\"<eos>\"])\n",
        "        elif self.task == \"classification\":\n",
        "            target = [self.labels[index]]\n",
        "        sample = {\n",
        "            \"source_sequence\": torch.tensor(source_sequence),\n",
        "            \"target\": torch.tensor(target),\n",
        "        }\n",
        "        return sample\n",
        "\n",
        "\n",
        "def MyCollator(batch):\n",
        "    source_sequences = pad_sequence(\n",
        "        #we use padding to match the length of the sequences in the same batch\n",
        "        [sample[\"source_sequence\"] for sample in batch], padding_value=token2ind[\"<pad>\"]\n",
        "    )\n",
        "    target = pad_sequence(\n",
        "        [sample[\"target\"] for sample in batch], padding_value=token2ind[\"<pad>\"]\n",
        "    )\n",
        "    return source_sequences, target.reshape(-1)\n",
        "\n",
        "\n",
        "def get_loader(\n",
        "    path_documents,\n",
        "    path_labels=None,\n",
        "    token2ind={},\n",
        "    max_len=512,\n",
        "    batch_size=32,\n",
        "    task=\"language_modeling\",\n",
        "):\n",
        "    dataset = Dataset(\n",
        "        path_documents,\n",
        "        path_labels=path_labels,\n",
        "        token2ind=token2ind,\n",
        "        max_len=512,\n",
        "        task=task,\n",
        "    )\n",
        "    data_loader = DataLoader(\n",
        "        dataset=dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=MyCollator,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "    return data_loader"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTns4lHrjUTa"
      },
      "source": [
        "## 5.The Training\n",
        "In this section we will implement a <code>train()</code> function that trains our model for one epoch. As we said, in this lab we will use a language modeling objective in\n",
        "the pretraining phase. Given the previous tokens in a sequence,\n",
        "the model will try to predict\n",
        "the next one. The same function can be used for both pretraining and fine-tuning phase.<br>\n",
        "\n",
        "The training procedure is as follows:<br>\n",
        "1. Iterate over the data-loader.<br>\n",
        "2. In each iteration perform one forward pass.<br>\n",
        "3. Compute\n",
        "the loss through back-propagation.<br>\n",
        "4. update\n",
        "the parameters of your model using sgd.<br>\n",
        "5. repeat for <i>n</i> epochs<br>\n",
        "\n",
        "<b>N.B:</b>  While in\n",
        "the <i>language_modeling</i> task all\n",
        "the vectors at\n",
        "the output of\n",
        "the base model are used, in\n",
        "the <i>classification</i> task we only use\n",
        "the vector representing\n",
        "the last token to perform\n",
        "the prediction.<br>\n",
        "\n",
        "<b><h4><font color='blue'>\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "Task 4: </b><br>\n",
        "Fill in the gaps in <code>train()</code> function.\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "</font></h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_jwosiLjRsS"
      },
      "source": [
        "def train(\n",
        "    path_data_train: str,\n",
        "    path_labels_train: Optional[str] = None,\n",
        "    path_data_valid: Optional[str] = None,\n",
        "    save_interval: int = -1,\n",
        "    log_interval: int = 5,\n",
        "    task: str = \"language_modeling\",\n",
        "    batch_size: int = 32,\n",
        ") -> List[float]:\n",
        "    \"\"\"\n",
        "    Trains the model for one epoch on the specified task (language modeling or classification).\n",
        "\n",
        "    This function loads the training data using a data loader, performs forward passes,\n",
        "    computes the cross-entropy loss, backpropagates the gradients, and updates the model's\n",
        "    parameters using an optimizer. It logs the average loss every `log_interval` steps and\n",
        "    returns a list of these average losses.\n",
        "\n",
        "    Args:\n",
        "        path_data_train (str): Path to the training data file.\n",
        "        path_labels_train (Optional[str]): Path to the training labels file (if applicable).\n",
        "        path_data_valid (Optional[str]): Path to the validation data file (if applicable).\n",
        "        save_interval (int): Interval at which to save model checkpoints (default: -1, meaning not used).\n",
        "        log_interval (int): Number of steps between loss logging (default: 5).\n",
        "        task (str): Task type, either \"language_modeling\" or \"classification\" (default: \"language_modeling\").\n",
        "        batch_size (int): Batch size to use during training (default: 32).\n",
        "\n",
        "    Returns:\n",
        "        List[float]: A list of average loss values logged during training.\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    ntokens = len(token2ind)\n",
        "    data_loader = get_loader(\n",
        "        path_data_train,\n",
        "        path_labels_train,\n",
        "        token2ind,\n",
        "        task=task,\n",
        "        batch_size=batch_size,\n",
        "    )\n",
        "\n",
        "    losses = []\n",
        "    for idx, data in enumerate(data_loader): #step 1\n",
        "        optimizer.zero_grad()\n",
        "        src_mask = model.base.generate_square_subsequent_mask(data[0].size(0)).to(\n",
        "            device\n",
        "        )\n",
        "        input = data[0].to(device)\n",
        "        output = model(input, src_mask) #step 2\n",
        "        if task == 'classification':\n",
        "            # last vector only\n",
        "            output = output[-1, :]\n",
        "        output = output.view(-1, output.shape[-1])\n",
        "        target =  data[1]\n",
        "        target = target.to(device)\n",
        "        loss =  criterion(output, target) #fill me, Cross entropy check next cells\n",
        "        #fill me step 3, backward propagation\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5) # prevent exploding gradient\n",
        "        #fill me step 4, optimizer step\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            cur_loss = total_loss / log_interval\n",
        "            print(\n",
        "                \"| epoch {:3d} | {:5d}/{:5d} steps | \"\n",
        "                \"loss {:5.5f} | ppl {:8.3f}\".format(\n",
        "                    epoch, idx, len(data_loader), cur_loss, math.exp(cur_loss),\n",
        "                )\n",
        "            )\n",
        "            losses.append(cur_loss)\n",
        "            total_loss = 0\n",
        "    return losses"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgf6BDB9jUr6"
      },
      "source": [
        "ntokens = len(token2ind) #fill me # the size of vocabulary\n",
        "nhid = 200  # the dimension of the feedforward network model in nn.TransformerEncoder\n",
        "nlayers = 4  # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2  # the number of heads in the multiheadattention models\n",
        "dropout = 0  # the dropout value\n",
        "\n",
        "nclasses = 2 # for classification task only\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens, dropout).to(device)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-OLy4KIkDwf"
      },
      "source": [
        "# optimization paramerters\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=token2ind['<pad>'])\n",
        "lr = 0.0003  # learning rate\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bwh3n9xZQy4e",
        "outputId": "f9c0621a-e6a8-4572-cfa8-eabe1de05da6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretraining_subset.txt\n",
        "path_data_train = \"pretraining_subset.txt\""
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-11 09:43:09--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretraining_subset.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10146460 (9.7M) [text/plain]\n",
            "Saving to: ‘pretraining_subset.txt.1’\n",
            "\n",
            "pretraining_subset. 100%[===================>]   9.68M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2025-02-11 09:43:09 (298 MB/s) - ‘pretraining_subset.txt.1’ saved [10146460/10146460]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m11g4ScjZaR",
        "outputId": "6ca9b16c-edc3-4f20-da6d-a598050f7243",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#pretraining on a tiny subset\n",
        "log_interval = 500\n",
        "epochs = 2\n",
        "for epoch in range(1, epochs + 1): #5\n",
        "    train(\n",
        "        path_data_train,\n",
        "        save_interval=-1,\n",
        "        task=\"language_modeling\",\n",
        "        batch_size=16,\n",
        "        log_interval=log_interval,\n",
        "    )"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   500/ 3125 steps | loss 7.30942 | ppl 1494.316\n",
            "| epoch   1 |  1000/ 3125 steps | loss 6.47200 | ppl  646.778\n",
            "| epoch   1 |  1500/ 3125 steps | loss 6.20084 | ppl  493.163\n",
            "| epoch   1 |  2000/ 3125 steps | loss 6.03431 | ppl  417.512\n",
            "| epoch   1 |  2500/ 3125 steps | loss 5.91701 | ppl  371.299\n",
            "| epoch   1 |  3000/ 3125 steps | loss 5.83891 | ppl  343.405\n",
            "| epoch   2 |   500/ 3125 steps | loss 5.52308 | ppl  250.404\n",
            "| epoch   2 |  1000/ 3125 steps | loss 5.47035 | ppl  237.543\n",
            "| epoch   2 |  1500/ 3125 steps | loss 5.45543 | ppl  234.027\n",
            "| epoch   2 |  2000/ 3125 steps | loss 5.41283 | ppl  224.265\n",
            "| epoch   2 |  2500/ 3125 steps | loss 5.38774 | ppl  218.708\n",
            "| epoch   2 |  3000/ 3125 steps | loss 5.32871 | ppl  206.173\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeOM1dOvkO4e"
      },
      "source": [
        "## 6. Text Generation\n",
        "Being trained on a language modeling objective, our model can be used in the inference mode to generate/complete sentences. However, the pretraining phase takes a lot of time compared to the fine-tuning. For example, <a href=\"https://arxiv.org/pdf/1911.03894.pdf\">CamemBERT</a><sub>base</sub> <sup>[1]</sup> was pretrained for 24 hours on 256 Nvidia V100 GPUs and <a href=\"https://arxiv.org/pdf/2010.12321.pdf\">BARThez</a> <sup>[2]</sup> was pretrained for 60h on 128 Nvidia V100 GPUs!<br>\n",
        "\n",
        "Of course, we don't have enough time and resources to efficiently pretrain our model, so instead we will load the weights from a checkpoint that has been pre-trained for 12 hours on 1 GPU.<br>\n",
        "\n",
        "Take a look here: <a href=\"https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-a-general-checkpoint-for-inference-and-or-resuming-training\">https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-a-general-checkpoint-for-inference-and-or-resuming-training</a><br>\n",
        "\n",
        "<b><h4><font color='blue'>\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "Task 5: </b><br>\n",
        "Implement the function <code>infer_next_tokens()</code> that takes as input a string <code>sent</code> and an integer <code>max_len</code> and returns a completion of the input sentence. The generation should stop when the model generates <code>&lt;eos&gt;</code> or the length of the generated sentence reaches <code>max_len</code>\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "</font></h4>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BcBC6FSkMH3",
        "outputId": "942807ce-c872-43d6-a302-74ac4404ec4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretrained_model_4layers.pt\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens).to(device)\n",
        "\n",
        "#load the checkpoint\n",
        "checkpoint = torch.load('pretrained_model_4layers.pt')\n",
        "#load state dict\n",
        "model.load_state_dict(checkpoint['model_state_dict'])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-11 09:46:10--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretrained_model_4layers.pt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 88093955 (84M) [application/octet-stream]\n",
            "Saving to: ‘pretrained_model_4layers.pt.1’\n",
            "\n",
            "pretrained_model_4l 100%[===================>]  84.01M   377MB/s    in 0.2s    \n",
            "\n",
            "2025-02-11 09:46:11 (377 MB/s) - ‘pretrained_model_4layers.pt.1’ saved [88093955/88093955]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-76a40ce8b80e>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load('pretrained_model_4layers.pt')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBRRVsWqlIoQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b3da5d9-b490-4524-898f-4f9dd138c41f"
      },
      "source": [
        "!pip install sentencepiece\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/sentencepiece.french.model\n",
        "\n",
        "import sentencepiece as spm\n",
        "\n",
        "s = spm.SentencePieceProcessor(model_file='sentencepiece.french.model') #load sentencepiece model\n",
        "\n",
        "#examples\n",
        "encoded = s.encode_as_pieces(\"Bonjour les amis!\")\n",
        "decoded = s.decode_pieces(encoded)\n",
        "print(encoded)\n",
        "print(decoded)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "--2025-02-11 09:46:14--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/sentencepiece.french.model\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115362 (1.1M) [application/octet-stream]\n",
            "Saving to: ‘sentencepiece.french.model.1’\n",
            "\n",
            "sentencepiece.frenc 100%[===================>]   1.06M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2025-02-11 09:46:14 (110 MB/s) - ‘sentencepiece.french.model.1’ saved [1115362/1115362]\n",
            "\n",
            "['▁Bonjour', '▁les', '▁amis', '!']\n",
            "Bonjour les amis!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded = s.encode_as_pieces(\"Coucou tout le monde\")\n",
        "decoded = s.decode_pieces(encoded)\n",
        "print(encoded)\n",
        "print(decoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5iqDT80v9Gx",
        "outputId": "f8e64518-decf-420c-aeae-ff8c86731df1"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['▁C', 'oucou', '▁tout', '▁le', '▁monde']\n",
            "Coucou tout le monde\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtLlV05pkQI3"
      },
      "source": [
        "def infer_next_token(sent: str) -> tuple[torch.Tensor, torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Generate the next token for a given input sentence using the model.\n",
        "\n",
        "    This function encodes the input sentence via SentencePiece, prepends a <sos> token,\n",
        "    and passes the resulting sequence through the model to obtain output logits. It then\n",
        "    selects the predicted token index from the logits corresponding to the last time step.\n",
        "\n",
        "    Args:\n",
        "        sent (str): The input sentence.\n",
        "\n",
        "    Returns:\n",
        "        tuple[torch.Tensor, torch.Tensor]: A tuple containing:\n",
        "            - next_token_ind: The predicted token index (as a torch.Tensor).\n",
        "            - out: The full output tensor from the model.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    sent_pieces = s.encode_as_pieces(sent)\n",
        "    source = [token2ind['<sos>']] + [token2ind[el] for el in sent_pieces]\n",
        "    source = torch.tensor(source).to(device)\n",
        "    source = source.reshape(-1, 1)\n",
        "    src_mask = model.base.generate_square_subsequent_mask(source.size(0)).to(device)\n",
        "    out = model(source, src_mask)\n",
        "    next_token_ind = out[-1].argmax(-1)\n",
        "    return next_token_ind, out\n",
        "\n",
        "def infer_next_tokens(sent: str, max_len: int = 50) -> str:\n",
        "    \"\"\"\n",
        "    Generate a sequence of tokens (text) by iteratively predicting the next token using the model.\n",
        "\n",
        "    This function encodes the input sentence, then repeatedly predicts the next token until\n",
        "    the maximum length is reached or an <eos> token is generated. The generated token indices\n",
        "    are converted back into text using SentencePiece.\n",
        "\n",
        "    Args:\n",
        "        sent (str): The initial input sentence.\n",
        "        max_len (int, optional): The maximum length of the generated sequence (including the initial tokens).\n",
        "                                 Defaults to 50.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text, with the initial <sos> token removed and truncated at <eos> if present.\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()\n",
        "    sent_pieces = s.encode_as_pieces(sent)\n",
        "    # Use get() to default to <oov> if the piece is not in token2ind.\n",
        "    source_tokens = [token2ind['<sos>']] + [token2ind.get(piece, token2ind['<oov>']) for piece in sent_pieces]\n",
        "\n",
        "    # Convert to tensor and reshape to [sequence_length, batch_size]\n",
        "    source = torch.tensor(source_tokens, dtype=torch.long, device=device).unsqueeze(1)\n",
        "\n",
        "    generated = source_tokens[:]\n",
        "\n",
        "    while len(generated) < max_len:\n",
        "\n",
        "        src_mask = model.base.generate_square_subsequent_mask(source.size(0)).to(device)\n",
        "        out = model(source, src_mask)\n",
        "\n",
        "        next_token_ind = out[-1].argmax(dim=-1).item()\n",
        "        generated.append(next_token_ind)\n",
        "        # If the generated token is <eos>, stop.\n",
        "        if next_token_ind == token2ind['<eos>']:\n",
        "            break\n",
        "        # Append the new token to the source tensor so that the model can condition on it in the next step.\n",
        "        next_token_tensor = torch.tensor([[next_token_ind]], dtype=torch.long, device=device)\n",
        "        source = torch.cat((source, next_token_tensor), dim=0)\n",
        "\n",
        "    # Remove the starting <sos> token.\n",
        "    generated = generated[1:]\n",
        "\n",
        "    if token2ind['<eos>'] in generated:\n",
        "        eos_index = generated.index(token2ind['<eos>'])\n",
        "        generated = generated[:eos_index]\n",
        "\n",
        "\n",
        "    generated_tokens = [ind2token[idx] for idx in generated]\n",
        "    # Use SentencePiece to decode the list of pieces back into a string.\n",
        "    generated_sentence = s.decode_pieces(generated_tokens)\n",
        "    return generated_sentence"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f83Nn5nSly4v",
        "outputId": "fe18724e-a3a7-475a-ba49-e7486ec92b53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "sent = \"Bonjour les\"\n",
        "infer_next_tokens(sent)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Bonjour les gens qui ont été très accueillants et sympathiques.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp7mjVzomoZ3"
      },
      "source": [
        "## 7. Supervised task\n",
        "It's time to train the model on the supervised task, which is in our case sentiment analysis. It consists of predicting whether a book review is a positive or a negative review. The model will be trained in 2 settings.<br>\n",
        "<ul>\n",
        "    <li>Training from scratch: All model parameters are randomly initialized.</li>\n",
        "    <li>Transfer learning: Only the classification head is trained from scratch, all other parameters are copied from the pre-trained model.</li>\n",
        "</ul>\n",
        "\n",
        "The training function is already implemented. However, to evaluate the model at each epoch we have to implement a function that computes the accuracy of the model on the validation set.<br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0K1BZsblmEmx",
        "outputId": "8aeb825b-a335-4228-91a2-d077e2f60e62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.review.spm\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.label\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.review.spm\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.label\n",
        "\n",
        "path_data_train = \"train.review.spm\"\n",
        "path_labels_train = \"train.label\"\n",
        "\n",
        "path_data_valid = \"test.review.spm\"\n",
        "path_labels_valid = \"test.label\""
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-11 09:46:14--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.review.spm\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1495960 (1.4M) [text/plain]\n",
            "Saving to: ‘train.review.spm.1’\n",
            "\n",
            "train.review.spm.1  100%[===================>]   1.43M  --.-KB/s    in 0.007s  \n",
            "\n",
            "2025-02-11 09:46:14 (214 MB/s) - ‘train.review.spm.1’ saved [1495960/1495960]\n",
            "\n",
            "--2025-02-11 09:46:14--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.label\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3200 (3.1K) [text/plain]\n",
            "Saving to: ‘train.label.1’\n",
            "\n",
            "train.label.1       100%[===================>]   3.12K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-02-11 09:46:15 (59.9 MB/s) - ‘train.label.1’ saved [3200/3200]\n",
            "\n",
            "--2025-02-11 09:46:15--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.review.spm\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1864544 (1.8M) [text/plain]\n",
            "Saving to: ‘test.review.spm.1’\n",
            "\n",
            "test.review.spm.1   100%[===================>]   1.78M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2025-02-11 09:46:15 (124 MB/s) - ‘test.review.spm.1’ saved [1864544/1864544]\n",
            "\n",
            "--2025-02-11 09:46:15--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.label\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4000 (3.9K) [text/plain]\n",
            "Saving to: ‘test.label.1’\n",
            "\n",
            "test.label.1        100%[===================>]   3.91K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-02-11 09:46:15 (20.3 MB/s) - ‘test.label.1’ saved [4000/4000]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b><h4><font color='blue'>\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "Task 6: </b><br>\n",
        "Implement the <code>accuracy()</code> function. This function takes as input a <code>data_loader</code> and returns an float.<br>\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "</font></h4>"
      ],
      "metadata": {
        "id": "vKMRmZD9abvd"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MLfvjiom2SL"
      },
      "source": [
        "# a function to evaluate the validation accuracy of the model.\n",
        "def evaluate_accuracy(data_loader: DataLoader) -> float:\n",
        "    \"\"\"\n",
        "    Compute the validation accuracy of the model.\n",
        "\n",
        "    Args:\n",
        "        data_loader (DataLoader): DataLoader yielding (src, target) batches.\n",
        "\n",
        "    Returns:\n",
        "        float: The accuracy as a fraction.\n",
        "    \"\"\"\n",
        "    #to be implemented\n",
        "    model.eval()  # set model to evaluation mode\n",
        "    running_correct = 0\n",
        "    running_total = 0\n",
        "    with torch.inference_mode():\n",
        "        for src, target in data_loader:\n",
        "            src, target = src.to(device), target.to(device)\n",
        "            src_mask = model.base.generate_square_subsequent_mask(src.size(0)).to(device)\n",
        "            logits = model(src, src_mask)\n",
        "            logits = logits[-1]\n",
        "            predictions = logits.argmax(dim=-1)\n",
        "            running_total += target.size(0)\n",
        "            running_correct += (predictions == target).sum().item()\n",
        "\n",
        "    return running_correct / running_total"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzmx7T7xoa6v"
      },
      "source": [
        "#save the base model to be loaded later in the fine-tuning phase\n",
        "torch.save({\"model_state_dict\": model.base.state_dict(),}, \"pretrained_model_4layers_no_class_head.pt\")"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-xclMCpnVpw",
        "outputId": "687230e2-0111-4ac2-b00c-40995358aff9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from_scratch_settings = [True, False]\n",
        "\n",
        "from_scratch_valid_acc = []\n",
        "pretrained_valid_acc = []\n",
        "lr = 0.0001\n",
        "\n",
        "for from_scratch in from_scratch_settings:\n",
        "    model = Model(ntokens, nhead, nhid, nlayers, 2, dropout).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    if not from_scratch:\n",
        "        print(\"=====PRETRAINED MODEL======\")\n",
        "        #load checkpoint\n",
        "        checkpoint = torch.load(\"pretrained_model_4layers_no_class_head.pt\")\n",
        "        #load state dict\n",
        "        model.base.load_state_dict(checkpoint['model_state_dict'])\n",
        "    else:\n",
        "        print(\"=====Trainig FROM SCRATCH======\")\n",
        "    epochs = 20\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train(\n",
        "            path_data_train,\n",
        "            path_labels_train,\n",
        "            save_interval=-1,\n",
        "            task='classification',\n",
        "            batch_size=8,\n",
        "            log_interval=50,\n",
        "        )\n",
        "        acc = evaluate_accuracy(\n",
        "            get_loader(\n",
        "                path_data_valid,\n",
        "                path_labels_valid,\n",
        "                token2ind=token2ind,\n",
        "                batch_size=20,\n",
        "                task='classification',\n",
        "            )\n",
        "        )\n",
        "        if from_scratch:\n",
        "            from_scratch_valid_acc.append(acc)\n",
        "        else:\n",
        "            pretrained_valid_acc.append(acc)\n",
        "    print()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=====Trainig FROM SCRATCH======\n",
            "| epoch   1 |    50/  200 steps | loss 0.78812 | ppl    2.199\n",
            "| epoch   1 |   100/  200 steps | loss 0.71347 | ppl    2.041\n",
            "| epoch   1 |   150/  200 steps | loss 0.70207 | ppl    2.018\n",
            "| epoch   2 |    50/  200 steps | loss 0.64365 | ppl    1.903\n",
            "| epoch   2 |   100/  200 steps | loss 0.61148 | ppl    1.843\n",
            "| epoch   2 |   150/  200 steps | loss 0.54338 | ppl    1.722\n",
            "| epoch   3 |    50/  200 steps | loss 0.30924 | ppl    1.362\n",
            "| epoch   3 |   100/  200 steps | loss 0.39342 | ppl    1.482\n",
            "| epoch   3 |   150/  200 steps | loss 0.31671 | ppl    1.373\n",
            "| epoch   4 |    50/  200 steps | loss 0.07770 | ppl    1.081\n",
            "| epoch   4 |   100/  200 steps | loss 0.17770 | ppl    1.194\n",
            "| epoch   4 |   150/  200 steps | loss 0.15335 | ppl    1.166\n",
            "| epoch   5 |    50/  200 steps | loss 0.02882 | ppl    1.029\n",
            "| epoch   5 |   100/  200 steps | loss 0.03972 | ppl    1.041\n",
            "| epoch   5 |   150/  200 steps | loss 0.02847 | ppl    1.029\n",
            "| epoch   6 |    50/  200 steps | loss 0.00027 | ppl    1.000\n",
            "| epoch   6 |   100/  200 steps | loss 0.00294 | ppl    1.003\n",
            "| epoch   6 |   150/  200 steps | loss 0.01722 | ppl    1.017\n",
            "| epoch   7 |    50/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   7 |   100/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   7 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   8 |    50/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   8 |   100/  200 steps | loss 0.00003 | ppl    1.000\n",
            "| epoch   8 |   150/  200 steps | loss 0.00012 | ppl    1.000\n",
            "| epoch   9 |    50/  200 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch   9 |   100/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   9 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  10 |    50/  200 steps | loss 0.00909 | ppl    1.009\n",
            "| epoch  10 |   100/  200 steps | loss 0.00084 | ppl    1.001\n",
            "| epoch  10 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  11 |    50/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  11 |   100/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  11 |   150/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  12 |    50/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  12 |   100/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  12 |   150/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  13 |    50/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  13 |   100/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  13 |   150/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |    50/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |   100/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |   150/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |    50/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |   100/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |   150/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  16 |    50/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  16 |   100/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  16 |   150/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  17 |    50/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  17 |   100/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  17 |   150/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  18 |    50/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  18 |   100/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  18 |   150/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  19 |    50/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  19 |   100/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  19 |   150/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  20 |    50/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  20 |   100/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  20 |   150/  200 steps | loss 0.00000 | ppl    1.000\n",
            "\n",
            "=====PRETRAINED MODEL======\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-45-4aa28422da9e>:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(\"pretrained_model_4layers_no_class_head.pt\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |    50/  200 steps | loss 0.81386 | ppl    2.257\n",
            "| epoch   1 |   100/  200 steps | loss 0.68024 | ppl    1.974\n",
            "| epoch   1 |   150/  200 steps | loss 0.57954 | ppl    1.785\n",
            "| epoch   2 |    50/  200 steps | loss 0.45448 | ppl    1.575\n",
            "| epoch   2 |   100/  200 steps | loss 0.50390 | ppl    1.655\n",
            "| epoch   2 |   150/  200 steps | loss 0.50461 | ppl    1.656\n",
            "| epoch   3 |    50/  200 steps | loss 0.40920 | ppl    1.506\n",
            "| epoch   3 |   100/  200 steps | loss 0.39354 | ppl    1.482\n",
            "| epoch   3 |   150/  200 steps | loss 0.41608 | ppl    1.516\n",
            "| epoch   4 |    50/  200 steps | loss 0.31283 | ppl    1.367\n",
            "| epoch   4 |   100/  200 steps | loss 0.26256 | ppl    1.300\n",
            "| epoch   4 |   150/  200 steps | loss 0.36013 | ppl    1.434\n",
            "| epoch   5 |    50/  200 steps | loss 0.18958 | ppl    1.209\n",
            "| epoch   5 |   100/  200 steps | loss 0.19260 | ppl    1.212\n",
            "| epoch   5 |   150/  200 steps | loss 0.17842 | ppl    1.195\n",
            "| epoch   6 |    50/  200 steps | loss 0.07593 | ppl    1.079\n",
            "| epoch   6 |   100/  200 steps | loss 0.08240 | ppl    1.086\n",
            "| epoch   6 |   150/  200 steps | loss 0.25667 | ppl    1.293\n",
            "| epoch   7 |    50/  200 steps | loss 0.04439 | ppl    1.045\n",
            "| epoch   7 |   100/  200 steps | loss 0.07411 | ppl    1.077\n",
            "| epoch   7 |   150/  200 steps | loss 0.07923 | ppl    1.082\n",
            "| epoch   8 |    50/  200 steps | loss 0.01064 | ppl    1.011\n",
            "| epoch   8 |   100/  200 steps | loss 0.01184 | ppl    1.012\n",
            "| epoch   8 |   150/  200 steps | loss 0.05964 | ppl    1.061\n",
            "| epoch   9 |    50/  200 steps | loss 0.00632 | ppl    1.006\n",
            "| epoch   9 |   100/  200 steps | loss 0.00101 | ppl    1.001\n",
            "| epoch   9 |   150/  200 steps | loss 0.00032 | ppl    1.000\n",
            "| epoch  10 |    50/  200 steps | loss 0.00015 | ppl    1.000\n",
            "| epoch  10 |   100/  200 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch  10 |   150/  200 steps | loss 0.00004 | ppl    1.000\n",
            "| epoch  11 |    50/  200 steps | loss 0.00119 | ppl    1.001\n",
            "| epoch  11 |   100/  200 steps | loss 0.02396 | ppl    1.024\n",
            "| epoch  11 |   150/  200 steps | loss 0.00003 | ppl    1.000\n",
            "| epoch  12 |    50/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  12 |   100/  200 steps | loss 0.00202 | ppl    1.002\n",
            "| epoch  12 |   150/  200 steps | loss 0.00367 | ppl    1.004\n",
            "| epoch  13 |    50/  200 steps | loss 0.00008 | ppl    1.000\n",
            "| epoch  13 |   100/  200 steps | loss 0.00010 | ppl    1.000\n",
            "| epoch  13 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  14 |    50/  200 steps | loss 0.00063 | ppl    1.001\n",
            "| epoch  14 |   100/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |   150/  200 steps | loss 0.00062 | ppl    1.001\n",
            "| epoch  15 |    50/  200 steps | loss 0.00004 | ppl    1.000\n",
            "| epoch  15 |   100/  200 steps | loss 0.00070 | ppl    1.001\n",
            "| epoch  15 |   150/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  16 |    50/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  16 |   100/  200 steps | loss 0.00010 | ppl    1.000\n",
            "| epoch  16 |   150/  200 steps | loss 0.00011 | ppl    1.000\n",
            "| epoch  17 |    50/  200 steps | loss 0.00043 | ppl    1.000\n",
            "| epoch  17 |   100/  200 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch  17 |   150/  200 steps | loss 0.01464 | ppl    1.015\n",
            "| epoch  18 |    50/  200 steps | loss 0.00009 | ppl    1.000\n",
            "| epoch  18 |   100/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  18 |   150/  200 steps | loss 0.01159 | ppl    1.012\n",
            "| epoch  19 |    50/  200 steps | loss 0.00032 | ppl    1.000\n",
            "| epoch  19 |   100/  200 steps | loss 0.01745 | ppl    1.018\n",
            "| epoch  19 |   150/  200 steps | loss 0.02830 | ppl    1.029\n",
            "| epoch  20 |    50/  200 steps | loss 0.04674 | ppl    1.048\n",
            "| epoch  20 |   100/  200 steps | loss 0.08680 | ppl    1.091\n",
            "| epoch  20 |   150/  200 steps | loss 0.05013 | ppl    1.051\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b><h4><font color='blue'>\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "Task 7: </b><br>\n",
        "Visualize the evolution of the accuracy of the model in function of the epoch in both settings.\n",
        "<hr style=\"border:10px solid blue\"> </hr>\n",
        "</font></h4>"
      ],
      "metadata": {
        "id": "KNyMCGV-a269"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCpBIdTHojm6",
        "outputId": "43f61a6d-e477-4d88-e3e6-19c41878f1a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "source": [
        "# Create a list of epoch numbers. For example, if you ran 15 epochs:\n",
        "epochs = range(1, len(from_scratch_valid_acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(epochs, from_scratch_valid_acc, marker='o', label='Training from Scratch')\n",
        "plt.plot(epochs, pretrained_valid_acc, marker='s', label='Transfer Learning')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Validation Accuracy\")\n",
        "plt.title(\" Accuracy Evolution Over Epochs\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b><h4><font color='red'>\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "Question 4 (4 points): </b><br>\n",
        "Interpret the results.\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "</font></h4>\n"
      ],
      "metadata": {
        "id": "L10PpUpxa86n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b><h4><font color='green'>\n",
        "<hr style=\"border:10px solid green\"> </hr>\n",
        "Answer 4: </b><br>\n",
        "\n",
        "The graph shows that the transfer learning curve is always higher than the training-from-scratch curve. This means that a model starting with pre-trained weights gets higher accuracy at every epoch compared to one that starts with random weights.\n",
        "\n",
        "In other words, the pre-trained model already contains useful feature representations that allow it to learn the classification task more quickly and effectively, resulting in faster convergence and better overall performance than starting with random weights.\n",
        "<hr style=\"border:10px solid green\"> </hr>\n",
        "</font></h4>\n"
      ],
      "metadata": {
        "id": "I7n4omIlbDhB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b><h4><font color='red'>\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "Question 5 (4 points): </b><br>\n",
        "What is one of the limitations of the language modeling objective used in this notebook, compared to the masked language model objective introduced in <a href=\"https://arxiv.org/abs/1810.04805\" target=\"_blank\">Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018). Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805.</a><br>\n",
        "<hr style=\"border:10px solid red\"> </hr>\n",
        "</font></h4>\n"
      ],
      "metadata": {
        "id": "QTIlxIVBbDrm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b><h4><font color='green'>\n",
        "<hr style=\"border:10px solid green\"> </hr>\n",
        "Answer 5: </b><br>\n",
        "\n",
        "One limitation of the autoregressive language modeling objective used here is that it is unidirectional and suffers from exposure bias, meaning the model is trained only on correct previous tokens and not on its own predictions. In contrast, consider the T5 model, which uses a span corruption objective (a variant of masked language modeling). T5 masks contiguous spans of text and trains the model to generate these missing spans using context from both the left and right. This bidirectional approach captures richer contextual information and mitigates the exposure bias problem.\n",
        "<hr style=\"border:10px solid green\"> </hr>\n",
        "</font></h4>\n"
      ],
      "metadata": {
        "id": "UsxL_yQHbEOh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NBdCxXSWXJGj"
      },
      "execution_count": 46,
      "outputs": []
    }
  ]
}