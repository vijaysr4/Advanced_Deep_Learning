{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FE2yoRM3vfpP"
      },
      "source": [
        "# CSC52087EP lab1a by Vicky Kalogeiton\n",
        "# Ecole Polytechnique\n",
        "# Basic GAN Notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cIRHe5qQgXG"
      },
      "outputs": [],
      "source": [
        "# import the libraries\n",
        "import torch, pdb\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.utils import make_grid\n",
        "from typing import Callable\n",
        "from tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jziRN9i4vpOZ"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXre4xVa8cQI"
      },
      "outputs": [],
      "source": [
        "# visualization function\n",
        "def show(tensor, ch=1, size=(28,28), num=16):\n",
        "  # tensor: 128 x 784 (Batch size = 128, 28*28 = 784)\n",
        "  data=tensor.detach().cpu().view(-1,ch,*size) # 128 x 784 --> 128 x 1 x 28 x 28\n",
        "  # matplotlib has a different order (Width ,Height ,Channels) than pytorch for images\n",
        "  grid = make_grid(data[:num], nrow=4).permute(1,2,0)   # 1 x 28 x 28  = 28 x 28 x 1\n",
        "  plt.imshow(grid)\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbH0CPD7-MnX"
      },
      "outputs": [],
      "source": [
        "# setup of the main parameters and hyperparameters\n",
        "epochs = 200\n",
        "cur_step = 0\n",
        "# every how many steps we want to show information on the screen\n",
        "info_step = 300\n",
        "mean_gen_loss = 0\n",
        "mean_disc_loss = 0\n",
        "\n",
        "#dimensionality of noise vector that is the input of the generator\n",
        "z_dim = 64\n",
        "# learning rate\n",
        "lr = 0.0002 #0.0001 #0.0002 # 0.00001\n",
        "\n",
        "# Binary Cross Entropy with Logits (transfoms the output wiht a sigmoid from 0 to 1)\n",
        "loss_func = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# batch size\n",
        "bs = 128\n",
        "device = 'cuda'\n",
        "print(device)\n",
        "\n",
        "# 1. where to store the data (.), 2. download the data = True 3. tranform according to the Tensor structure\n",
        "# 4. shuffle: at every epoch we shuffle the data, 5. batch size\n",
        "dataloader = DataLoader(MNIST('.', download=True, transform=transforms.ToTensor()),shuffle=True, batch_size=bs)\n",
        "\n",
        "# every epoch is going to have number of steps:\n",
        "# number of steps = 60000 / 128 = 468.75"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYdmi5MwvUnx"
      },
      "source": [
        "## Declare the models\n",
        "#### Fill in the missing blanks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exkhTQ5pvs__"
      },
      "outputs": [],
      "source": [
        "# Generator\n",
        "def generatorBlock(input, output):\n",
        "  return nn.Sequential(\n",
        "    nn.Linear(input, output),   # Linear Layer (use torch.nn)\n",
        "    nn.BatchNorm1d(output),   # Batch Norm 1d\n",
        "    nn.ReLU(),   # ReLU\n",
        "  )\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, z_dim=64, image_dim=784, h_dim=128): # z_dim: latent space dimensionality\n",
        "    super().__init__()\n",
        "    self.generator = nn.Sequential( # Fill in the rest by using the z_dim and the h_dim\n",
        "        generatorBlock(z_dim, h_dim), # 64 --> 128\n",
        "        generatorBlock(h_dim, h_dim * 2), # 128 --> 256\n",
        "        generatorBlock(h_dim * 2, h_dim * 4), # 256 --> 512\n",
        "        generatorBlock(h_dim * 4, h_dim * 8), # 512 --> 1024\n",
        "        generatorBlock(h_dim * 8, image_dim), # 1024 --> 784 (28x28)\n",
        "        nn.Sigmoid(), # to make the values between 0 and 1\n",
        "    )\n",
        "\n",
        "  def forward(self, noise):\n",
        "       return self.generator(noise)\n",
        "\n",
        "# function that generates noise\n",
        "def gen_noise(number, z_dim):\n",
        "  return torch.randn(number, z_dim).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HeJ7MsFSDn9o"
      },
      "outputs": [],
      "source": [
        "## Discriminator\n",
        "def discriminatorBlock(input, output):\n",
        "  return nn.Sequential(\n",
        "      nn.Linear(input, output),   # Linear Layer\n",
        "      nn.LeakyReLU(0.2),   # LeakyReLU default 0.1\n",
        "  )\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, image_dim=784, h_dim=256):\n",
        "    super().__init__()\n",
        "    self.discriminator=nn.Sequential( # Fill in the rest by using the image_dim and the h_dim\n",
        "        discriminatorBlock(image_dim, h_dim * 4), # 784 --> 1024\n",
        "        discriminatorBlock(h_dim * 4, h_dim * 2), # 1024 --> 512\n",
        "        discriminatorBlock(h_dim * 2, h_dim), # 512 --> 256\n",
        "        nn.Linear(h_dim, 1) # output: 256 --> 1\n",
        "    )\n",
        "\n",
        "  def forward(self, image):\n",
        "      return self.discriminator(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNwv_Hls5VCR"
      },
      "source": [
        "## Main code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "seszPPbBOc1r"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "gen = Generator(z_dim).to(device)\n",
        "# optimizer of the generator\n",
        "gen_opt = optim.Adam(gen.parameters()) # Adam optimizer\n",
        "disc = Discriminator().to(device)\n",
        "# optimizer of the discriminator\n",
        "disc_opt = optim.Adam(disc.parameters())  # Adam optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_9mS9dPPpNa"
      },
      "outputs": [],
      "source": [
        "# check your generator\n",
        "gen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dpl4G5NEPrJQ"
      },
      "outputs": [],
      "source": [
        "# check your discriminator\n",
        "disc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LMJkT1f57pE"
      },
      "outputs": [],
      "source": [
        "x,y=next(iter(dataloader))\n",
        "print(x.shape, y.shape)\n",
        "print(y[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGjXIihPReLx"
      },
      "outputs": [],
      "source": [
        "noise = gen_noise(bs, z_dim)\n",
        "fake = gen(noise)\n",
        "show(fake)\n",
        "\n",
        "# Here we see the initial output of passing the noise through the generator\n",
        "# Since the generator did not start learning, it produces a very noisy output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e0PSVDj6Q9G"
      },
      "source": [
        "## Compute the loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsZzz3irTSh_"
      },
      "outputs": [],
      "source": [
        "# generator loss\n",
        "def calc_gen_loss(loss_func: Callable[[torch.Tensor, torch.Tensor], torch.Tensor],\n",
        "                  gen: nn.Module,\n",
        "                  disc: nn.Module,\n",
        "                  number: int,\n",
        "                  z_dim: int) -> torch.Tensor: # number is the number of elemenent we want to process, i.e. batch size\n",
        "    \"\"\"\n",
        "    Calculate the generator's loss in a GAN setup.\n",
        "\n",
        "    Args:\n",
        "        loss_func (torch.nn.Module): The loss function to compute the generator loss (e.g., BCEWithLogitsLoss).\n",
        "        gen (torch.nn.Module): The generator model.\n",
        "        disc (torch.nn.Module): The discriminator model.\n",
        "        number (int): The batch size (number of samples to process in this step).\n",
        "        z_dim (int): Dimensionality of the noise vector (latent space).\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The computed generator loss.\n",
        "    \"\"\"\n",
        "    noise = gen_noise(number, z_dim)\n",
        "    fake = gen(noise)\n",
        "    pred = disc(fake)\n",
        "    targets=torch.ones_like(pred) # 1: real, 0: fake\n",
        "    gen_loss=loss_func(pred,targets)\n",
        "\n",
        "    return gen_loss\n",
        "\n",
        "\n",
        "def calc_disc_loss(loss_func: Callable[[torch.Tensor, torch.Tensor], torch.Tensor],\n",
        "                  gen: nn.Module,\n",
        "                  disc: nn.Module,\n",
        "                  number: int,\n",
        "                  real: torch.Tensor,\n",
        "                  z_dim: int) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Calculate the discriminator's loss in a GAN setup.\n",
        "\n",
        "    Args:\n",
        "        loss_func (torch.nn.Module): The loss function to compute the discriminator loss (e.g., BCEWithLogitsLoss).\n",
        "        gen (torch.nn.Module): The generator model.\n",
        "        disc (torch.nn.Module): The discriminator model.\n",
        "        number (int): The batch size (number of samples to process in this step).\n",
        "        real (torch.Tensor): A batch of real images.\n",
        "        z_dim (int): Dimensionality of the noise vector (latent space).\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The computed discriminator loss.\n",
        "    \"\"\"\n",
        "\n",
        "    # number is the number of elemenent we want to process, i.e. batch size\n",
        "    # real is the number of real images\n",
        "    noise = gen_noise(number, z_dim)\n",
        "    fake = gen(noise)\n",
        "    disc_fake = disc(fake.detach()) # need to detach so that we do not change the generator\n",
        "    disc_fake_targets=torch.zeros_like(disc_fake) # 1: real, 0: fake\n",
        "    disc_fake_loss=loss_func(disc_fake, disc_fake_targets)\n",
        "\n",
        "    disc_real = disc(real)\n",
        "    disc_real_targets=torch.ones_like(disc_real)\n",
        "    disc_real_loss=loss_func(disc_real, disc_real_targets)\n",
        "\n",
        "    disc_loss=(disc_fake_loss+disc_real_loss)/2\n",
        "\n",
        "    return disc_loss\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtVhFT_urT53"
      },
      "source": [
        "\n",
        "**GANs are known for their training instability and difficulty in achieving convergence. Discuss the potential causes of these issues**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Causes of Training Instability and Difficulty in GANs:\n",
        "- ```Non-convergence of Loss Functions:``` GANs aim for a Nash equilibrium where the generator and discriminator are perfectly balanced. This is often hard to achieve as the optimization of two competing objectives may not converge smoothly.\n",
        "\n",
        "- ```Mode Collapse:``` The generator may produce limited variations of data (or even a single mode), leading to a lack of diversity in generated outputs.\n",
        "\n",
        "- ```Vanishing Gradients:``` If the discriminator becomes too strong, the generator's gradients diminish, leading to slower learning.\n",
        "\n",
        "- ```Imbalance in Generator & Discriminator Training:``` If one model (generator or discriminator) significantly outpaces the other during training, it can cause instability. For example, a highly capable discriminator might overpower the generator and lead to no meaningful updates.\n",
        "\n",
        "- ```Lack of Proper Regularization:``` Overfitting in the discriminator or improper handling of the generator's outputs can lead to instability.\n",
        "\n",
        "- ```Sensitivity to Hyperparameters:``` GANs are highly sensitive to learning rates, batch sizes, and other hyperparameters. Slight deviations may lead to poor convergence or collapse.\n",
        "\n",
        "- ```Noisy Gradient Updates:``` The stochasticity inherent in gradient-based optimization can lead to oscillations or divergence in training."
      ],
      "metadata": {
        "id": "ihJ3OisbxdbB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTJkJcnP7ao9"
      },
      "source": [
        "## Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPcL8U6BXMZv"
      },
      "outputs": [],
      "source": [
        "### batch size = 128\n",
        "### 60000 / 128 = 468.75  = 469 steps in each epoch\n",
        "### Each step is going to process 128 images = size of the batch (except the last step)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for real, _ in tqdm(dataloader):\n",
        "    ### discriminator\n",
        "    disc_opt.zero_grad(), # set the gradients to zero\n",
        "\n",
        "\n",
        "    current_batch_size=len(real) # real: 128 x 1 x 28 x 28\n",
        "    real = real.view(current_batch_size, -1) # 128 x 784\n",
        "    real = real.to(device)\n",
        "\n",
        "    disc_loss = calc_disc_loss(loss_func,gen,disc,current_batch_size,real,z_dim)\n",
        "    disc_loss.backward(), # Backpropagation\n",
        "    disc_opt.step, # Optimizer step\n",
        "\n",
        "    ### generator\n",
        "    gen_opt.zero_grad() , # set the gradients to zero\n",
        "    gen_loss = calc_gen_loss(loss_func,gen,disc,current_batch_size,z_dim)\n",
        "    gen_loss.backward(), # Backpropagation\n",
        "    gen_opt.step(), # Optimizer step\n",
        "\n",
        "    ### statistics + visualization\n",
        "\n",
        "    # adding the values into the losses\n",
        "    mean_disc_loss+=disc_loss.item()/info_step # .item() transforms the tensor value into a standalone value\n",
        "    mean_gen_loss+=gen_loss.item()/info_step\n",
        "\n",
        "    if cur_step % info_step == 0 and cur_step>0:\n",
        "      fake_noise = gen_noise(current_batch_size, z_dim)\n",
        "      fake = gen(fake_noise)\n",
        "      show(fake)\n",
        "      show(real)\n",
        "      print(f\"{epoch}: step {cur_step} / Gen loss: {mean_gen_loss} / disc_loss: {mean_disc_loss}\")\n",
        "      mean_gen_loss, mean_disc_loss=0,0\n",
        "    cur_step+=1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observed Score:\n",
        "\n",
        "```lr: 0.0001:``` Gen_loss = 0.587, disc_loss = 0.705\n",
        "\n",
        "```lr: 0.00002:``` Gen_loss = 0.595, disc_loss = 0.750"
      ],
      "metadata": {
        "id": "R2hhMiW6ORWW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Zy3mAZutQfk"
      },
      "source": [
        "**In the quantitative assessment of GANs, especially for complex image datasets, which metrics are suitable for evaluating the quality and diversity of the generated images?**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Suitable Metrics for Evaluating GANs on Complex Datasets:\n",
        "\n",
        "```Fréchet Inception Distance (FID):```\n",
        "\n",
        "- Measures the similarity between the distributions of real and generated images in the feature space of a pre-trained model.\n",
        "- Lower FID scores indicate higher similarity between generated and real images.\n",
        "\n",
        "```Inception Score (IS): ```\n",
        "- Evaluates the quality and diversity of generated images.\n",
        "- A higher IS indicates that images are meaningful and belong to a variety of categories.\n",
        "\n",
        "```Precision and Recall for Distributions:```\n",
        "\n",
        "- Measures the quality (precision) and diversity (recall) of generated samples relative to real samples.\n",
        "\n",
        "```Kernel Inception Distance (KID):```\n",
        "\n",
        "- Similar to FID but uses polynomial kernel methods for a more robust comparison.\n",
        "\n",
        "\n",
        "```Diversity Score:```\n",
        "\n",
        "- Evaluates the variance across the generated images, highlighting the generator's ability to produce diverse samples."
      ],
      "metadata": {
        "id": "IhtgfB3jwrwz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CNc2arSLxasO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}